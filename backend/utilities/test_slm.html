<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Phi3-mini Streaming Test</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 2rem; }
    textarea { width: 100%; height: 100px; box-sizing: border-box; }
    h2 { margin-top: 2rem; border-bottom: 1px solid #ccc; padding-bottom: 0.5rem; }
    .response-container { display: flex; gap: 20px; margin-top: 1rem; }
    .response-box { flex: 1; border: 1px solid #ccc; padding: 1rem; }
    .response-box pre { background: #f9f9f9; padding: 0.5rem; white-space: pre-wrap; min-height: 150px; margin: 0; }
    button { padding: 0.75rem 1.5rem; margin-top: 1rem; background-color: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; }
    button:hover { background-color: #0056b3; }
  </style>
</head>
<body>
  <h1>Phi3-mini API Test (localhost:8080)</h1>
  <textarea id="prompt" placeholder="Type your prompt here (e.g., 'Explain the difference between streaming and non-streaming API responses in one paragraph')." rows="5"></textarea>
  <br>
  <button onclick="sendPrompt()">Send Prompt</button>

  <h2>Responses</h2>

  <div class="response-container">
    <div class="response-box">
      <h3>1. Non-Streaming Response (Loads, then shows all at once)</h3>
      <pre id="response-full">Click 'Send Prompt' to test...</pre>
    </div>

    <div class="response-box">
      <h3>2. Streaming Response (Shows token by token)</h3>
      <pre id="response-stream">Click 'Send Prompt' to test...</pre>
    </div>
  </div>

  <script>
    const API_URL = "http://localhost:8081/v1/chat/completions";

    async function sendPrompt() {
      const prompt = document.getElementById("prompt").value.trim();
      const fullEl = document.getElementById("response-full");
      const streamEl = document.getElementById("response-stream");

      if (!prompt) {
        alert("Please enter a prompt.");
        return;
      }

      // 1. Setup UI for loading states
      fullEl.textContent = "Loading... (Waiting for full response)";
      streamEl.textContent = "Streaming... (Start token by token)";

      // 2. Start both requests concurrently
      Promise.all([
        getNonStreamingResponse(prompt, fullEl),
        getStreamingResponse(prompt, streamEl)
      ]).catch(err => {
        console.error("An error occurred during API calls:", err);
        // Fallback error message if a critical error prevents individual handlers from running
        if (fullEl.textContent.startsWith("Loading")) fullEl.textContent = "Critical Error: See console.";
        if (streamEl.textContent.startsWith("Streaming")) streamEl.textContent = "Critical Error: See console.";
      });
    }

    // =================================================================
    // 1. NON-STREAMING FUNCTION (stream: false)
    // =================================================================
    async function getNonStreamingResponse(prompt, element) {
      try {
        const payload = {
          messages: [{ role: "user", content: prompt }],
          stream: false, // The key difference: wait for the whole thing
          max_tokens: 800,
          temperature: 0.7
        };

        const res = await fetch(API_URL, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(payload)
        });

        if (!res.ok) {
          element.textContent = `Error: ${res.status} ${res.statusText}`;
          return;
        }

        const data = await res.json();
        
        // Extract the content from the standard OpenAI chat/completions response
        const text = data.choices[0].message.content || "";
        element.textContent = text.trim();

      } catch (err) {
        element.textContent = `Error: ${err.message}. Ensure your Docker is running and accessible.`;
        console.error("Non-Streaming Error:", err);
      }
    }

    // =================================================================
    // 2. STREAMING FUNCTION (stream: true)
    // =================================================================
    async function getStreamingResponse(prompt, element) {
      element.textContent = ""; // Clear initial 'Streaming...' message

      try {
        const payload = {
          messages: [{ role: "user", content: prompt }],
          stream: true, // The key difference: stream data back
          max_tokens: 800,
          temperature: 0.7
        };

        const res = await fetch(API_URL, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(payload)
        });

        if (!res.ok) {
          element.textContent = `Error: ${res.status} ${res.statusText}`;
          return;
        }

        // Use a TextDecoder to read the stream data as it arrives
        const reader = res.body.getReader();
        const decoder = new TextDecoder("utf-8");
        let done = false;

        while (!done) {
          const { value, done: readerDone } = await reader.read();
          done = readerDone;

          if (value) {
            // Process the chunk of data
            const chunk = decoder.decode(value, { stream: true });
            
            // The llama.cpp server uses "data: {json}\n\n" Server-Sent Events (SSE) format
            // We split by "data: " to process each message
            const lines = chunk.split('\n');
            for (const line of lines) {
                if (line.startsWith("data:")) {
                    try {
                        const jsonStr = line.substring(5).trim();
                        if (jsonStr === "[DONE]") {
                            done = true;
                            break;
                        }
                        
                        const data = JSON.parse(jsonStr);
                        // Extract content from the choice delta
                        const content = data.choices[0].delta.content || "";
                        
                        // Append the new token to the response box
                        element.textContent += content;
                        
                        // Optional: Scroll to bottom as content is added
                        element.scrollTop = element.scrollHeight;

                    } catch (e) {
                        // console.warn("Could not parse JSON chunk:", e, line);
                    }
                }
            }
          }
        }
        
        if (element.textContent === "") {
            element.textContent = "No content received. Check server logs."
        }


      } catch (err) {
        element.textContent = `Error: ${err.message}. Ensure your Docker is running and accessible.`;
        console.error("Streaming Error:", err);
      }
    }
  </script>
</body>
</html>